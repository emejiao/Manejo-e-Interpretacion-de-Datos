{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"alert alert-success\" role=\"alert\">\n",
    "  <h1 class=\"alert-heading\">Regresión Ridge</h1>\n",
    "  <h3 class=\"alert-heading\">Prof. Enrique Mejía Ospino, emejia@uis.edu.co</h3>\n",
    "  <h4 class=\"alert-heading\">Escuela de Química</h4>\n",
    "  <h5 class=\"alert-heading\">Universidad Industrial de Santander</h5>\n",
    "  <p>\n",
    "  </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import scale \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge, RidgeCV, Lasso, LassoCV\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:justify\">\n",
    "\n",
    "<font color=red size=6>**Regresión Ridge**\n",
    "\n",
    "<font color=blue>**La Regresión Rigde, también denominada regresión contraída o Tikhonov regularization, regulariza el modelo resultante imponiendo una penalización al tamaño de los coeficientes de la relación lineal entre las características predictivas y la variable objetivo. En este caso, los coeficientes calculados minimizan la suma de los cuadrados de los residuos penalizada al añadir el cuadrado de la norma L2 del vector formado por los coeficientes:**\n",
    "$$RSS_{Ridge}= \\sum_{i=0}^n (y_i - f(x_i))^2 + \\lambda\\sum_{j=0}^p \\beta_j^2$$\n",
    "$$\\sum^n_{i=1}(y_i - \\beta_0 - \\sum^p_{j=1} \\beta_j x_{ij})^2 + \\lambda \\sum^p_{j=1} \\beta_j^2 = \\text{suma residuos cuadrados} + \\lambda \\sum^p_{j=1} \\beta_j^2$$\n",
    "<font color=blue>**donde λ es un parámetro que controla el grado de penalización: cuanto mayor éste, los coeficientes serán menores, resultando más robustos a la colinealidad.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=black>**La principal ventaja de aplicar Ridge frente al ajuste por mínimos cuadrados ordinarios (OLS) es la reducción de varianza. Por lo general, en situaciones en las que la relación entre la variable respuesta y los predictores es aproximadamente lineal, las estimaciones por mínimos cuadrados tienen poco bias (sesgo) pero aún pueden sufrir alta varianza (pequeños cambios en los datos de entrenamiento tienen mucho impacto en el modelo resultante). Este problema se acentúa conforme el número de predictores introducido en el modelo se aproxima al número de observaciones de entrenamiento, llegando al punto en que, si p>n, no es posible ajustar el modelo por mínimos cuadrados ordinarios. Empleando un valor adecuado de λ, el método de ridge es capaz de reducir varianza sin apenas aumentar el bias, consiguiendo así un menor error total.**\n",
    "\n",
    "<font color=red>**La desventaja del método ridge es que, el modelo final, incluye todos los predictores. Esto es así porque, si bien la penalización fuerza a que los coeficientes tiendan a cero, nunca llegan a ser exactamente cero (solo si λ=∞). Este método consigue minimizar la influencia sobre el modelo de los predictores menos relacionados con la variable respuesta pero, en el modelo final, van a seguir apareciendo. Aunque esto no supone un problema para la precisión del modelo, sí lo es para su interpretación.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'.. _diabetes_dataset:\\n\\nDiabetes dataset\\n----------------\\n\\nTen baseline variables, age, sex, body mass index, average blood\\npressure, and six blood serum measurements were obtained for each of n =\\n442 diabetes patients, as well as the response of interest, a\\nquantitative measure of disease progression one year after baseline.\\n\\n**Data Set Characteristics:**\\n\\n  :Number of Instances: 442\\n\\n  :Number of Attributes: First 10 columns are numeric predictive values\\n\\n  :Target: Column 11 is a quantitative measure of disease progression one year after baseline\\n\\n  :Attribute Information:\\n      - age     age in years\\n      - sex\\n      - bmi     body mass index\\n      - bp      average blood pressure\\n      - s1      tc, T-Cells (a type of white blood cells)\\n      - s2      ldl, low-density lipoproteins\\n      - s3      hdl, high-density lipoproteins\\n      - s4      tch, thyroid stimulating hormone\\n      - s5      ltg, lamotrigine\\n      - s6      glu, blood sugar level\\n\\nNote: Each of these 10 feature variables have been mean centered and scaled by the standard deviation times `n_samples` (i.e. the sum of squares of each column totals 1).\\n\\nSource URL:\\nhttps://www4.stat.ncsu.edu/~boos/var.select/diabetes.html\\n\\nFor more information see:\\nBradley Efron, Trevor Hastie, Iain Johnstone and Robert Tibshirani (2004) \"Least Angle Regression,\" Annals of Statistics (with discussion), 407-499.\\n(https://web.stanford.edu/~hastie/Papers/LARS/LeastAngle_2002.pdf)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets, linear_model\n",
    "diabetes = datasets.load_diabetes()\n",
    "X = diabetes.data[:200]\n",
    "y = diabetes.target[:200]\n",
    "diabetes['feature_names']\n",
    "diabetes['DESCR']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red> **Convertimos los datos a DataFrame.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>bmi</th>\n",
       "      <th>bp</th>\n",
       "      <th>s1</th>\n",
       "      <th>s2</th>\n",
       "      <th>s3</th>\n",
       "      <th>s4</th>\n",
       "      <th>s5</th>\n",
       "      <th>s6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.038076</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.061696</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>-0.044223</td>\n",
       "      <td>-0.034821</td>\n",
       "      <td>-0.043401</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.019908</td>\n",
       "      <td>-0.017646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.001882</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>-0.019163</td>\n",
       "      <td>0.074412</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.068330</td>\n",
       "      <td>-0.092204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.085299</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.044451</td>\n",
       "      <td>-0.005671</td>\n",
       "      <td>-0.045599</td>\n",
       "      <td>-0.034194</td>\n",
       "      <td>-0.032356</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>0.002864</td>\n",
       "      <td>-0.025930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.089063</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.011595</td>\n",
       "      <td>-0.036656</td>\n",
       "      <td>0.012191</td>\n",
       "      <td>0.024991</td>\n",
       "      <td>-0.036038</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.022692</td>\n",
       "      <td>-0.009362</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.005383</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.036385</td>\n",
       "      <td>0.021872</td>\n",
       "      <td>0.003935</td>\n",
       "      <td>0.015596</td>\n",
       "      <td>0.008142</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.031991</td>\n",
       "      <td>-0.046641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>0.027178</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.025051</td>\n",
       "      <td>0.014987</td>\n",
       "      <td>0.025950</td>\n",
       "      <td>0.048477</td>\n",
       "      <td>-0.039719</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.007837</td>\n",
       "      <td>0.023775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>-0.023677</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.046085</td>\n",
       "      <td>-0.033214</td>\n",
       "      <td>0.032830</td>\n",
       "      <td>0.036264</td>\n",
       "      <td>0.037595</td>\n",
       "      <td>-0.002592</td>\n",
       "      <td>-0.033249</td>\n",
       "      <td>0.011349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>0.048974</td>\n",
       "      <td>0.050680</td>\n",
       "      <td>0.003494</td>\n",
       "      <td>0.070073</td>\n",
       "      <td>-0.008449</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>-0.054446</td>\n",
       "      <td>0.034309</td>\n",
       "      <td>0.013316</td>\n",
       "      <td>0.036201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>-0.052738</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>0.054152</td>\n",
       "      <td>-0.026328</td>\n",
       "      <td>-0.055231</td>\n",
       "      <td>-0.033881</td>\n",
       "      <td>-0.013948</td>\n",
       "      <td>-0.039493</td>\n",
       "      <td>-0.074089</td>\n",
       "      <td>-0.059067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>0.041708</td>\n",
       "      <td>-0.044642</td>\n",
       "      <td>-0.045007</td>\n",
       "      <td>0.034496</td>\n",
       "      <td>0.043837</td>\n",
       "      <td>-0.015719</td>\n",
       "      <td>0.037595</td>\n",
       "      <td>-0.014401</td>\n",
       "      <td>0.089899</td>\n",
       "      <td>0.007207</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          age       sex       bmi        bp        s1        s2        s3  \\\n",
       "0    0.038076  0.050680  0.061696  0.021872 -0.044223 -0.034821 -0.043401   \n",
       "1   -0.001882 -0.044642 -0.051474 -0.026328 -0.008449 -0.019163  0.074412   \n",
       "2    0.085299  0.050680  0.044451 -0.005671 -0.045599 -0.034194 -0.032356   \n",
       "3   -0.089063 -0.044642 -0.011595 -0.036656  0.012191  0.024991 -0.036038   \n",
       "4    0.005383 -0.044642 -0.036385  0.021872  0.003935  0.015596  0.008142   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "195  0.027178  0.050680  0.025051  0.014987  0.025950  0.048477 -0.039719   \n",
       "196 -0.023677 -0.044642 -0.046085 -0.033214  0.032830  0.036264  0.037595   \n",
       "197  0.048974  0.050680  0.003494  0.070073 -0.008449  0.013404 -0.054446   \n",
       "198 -0.052738 -0.044642  0.054152 -0.026328 -0.055231 -0.033881 -0.013948   \n",
       "199  0.041708 -0.044642 -0.045007  0.034496  0.043837 -0.015719  0.037595   \n",
       "\n",
       "           s4        s5        s6  \n",
       "0   -0.002592  0.019908 -0.017646  \n",
       "1   -0.039493 -0.068330 -0.092204  \n",
       "2   -0.002592  0.002864 -0.025930  \n",
       "3    0.034309  0.022692 -0.009362  \n",
       "4   -0.002592 -0.031991 -0.046641  \n",
       "..        ...       ...       ...  \n",
       "195  0.034309  0.007837  0.023775  \n",
       "196 -0.002592 -0.033249  0.011349  \n",
       "197  0.034309  0.013316  0.036201  \n",
       "198 -0.039493 -0.074089 -0.059067  \n",
       "199 -0.014401  0.089899  0.007207  \n",
       "\n",
       "[200 rows x 10 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=pd.DataFrame(X)\n",
    "X=X.set_axis(diabetes['feature_names'], axis=1, inplace=False).astype('float64')\n",
    "#X_ = X.drop(['Salary', 'League', 'Division', 'NewLeague'], axis = 1).astype('float64')\n",
    "y=pd.DataFrame(y)\n",
    "y=y.set_axis(['R'], axis=1, inplace=False)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue> **Usaremos la librería `sklearn` para realizar la Regresión Ridge regression. Las principales funciones para de desarrollar este tipo de regresión son `Ridge()`, para construir los modelos. Adicionalmente es posible hacer validación-cruzada: `RidgeCV()` y otras operaciones.** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**La función `Ridge()` tiene un argunmento llamado alpha ($\\alpha$) (que corresponde a $\\lambda$, en la ecuación de arriba!) que se usa para sintonizar el modelo. Inicialmente generaremos un arreglo de valores de $\\alpha$ de muy grandes a valores muy pequeños, de tal forma que podemos obtener modelo que van desde el modelo nulo (con solo el intercepto) y el ajuste por mínimos cuadrados.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.00000000e+09, 1.47814441e+09, 1.09245544e+09, 8.07403452e+08,\n",
       "       5.96729448e+08, 4.41026148e+08, 3.25950167e+08, 2.40900708e+08,\n",
       "       1.78043017e+08, 1.31586645e+08, 9.72520316e+07, 7.18762733e+07,\n",
       "       5.31217557e+07, 3.92608130e+07, 2.90165756e+07, 2.14453444e+07,\n",
       "       1.58496580e+07, 1.17140416e+07, 8.65752256e+06, 6.39853428e+06,\n",
       "       4.72897883e+06, 3.49505680e+06, 2.58309933e+06, 1.90909691e+06,\n",
       "       1.41096046e+06, 1.04280166e+06, 7.70705719e+05, 5.69607174e+05,\n",
       "       4.20980829e+05, 3.11135229e+05, 2.29951399e+05, 1.69950687e+05,\n",
       "       1.25605829e+05, 9.28317767e+04, 6.86093857e+04, 5.07072899e+04,\n",
       "       3.74763485e+04, 2.76977274e+04, 2.04706204e+04, 1.51292666e+04,\n",
       "       1.11816204e+04, 8.26402480e+03, 6.10771102e+03, 4.51403944e+03,\n",
       "       3.33620107e+03, 2.46569348e+03, 1.82232551e+03, 1.34683013e+03,\n",
       "       9.95404713e+02, 7.35675954e+02, 5.43717649e+02, 4.01846601e+02,\n",
       "       2.96993652e+02, 2.19499753e+02, 1.62226166e+02, 1.19896850e+02,\n",
       "       8.86124292e+01, 6.54909833e+01, 4.84025653e+01, 3.57729906e+01,\n",
       "       2.64388230e+01, 1.95401991e+01, 1.44416180e+01, 1.06733985e+01,\n",
       "       7.88841212e+00, 5.83010613e+00, 4.30886938e+00, 3.18456559e+00,\n",
       "       2.35362390e+00, 1.73949801e+00, 1.28561462e+00, 9.50162032e-01,\n",
       "       7.02238347e-01, 5.19004842e-01, 3.83582052e-01, 2.83494833e-01,\n",
       "       2.09523151e-01, 1.54852737e-01, 1.14447353e-01, 8.45848575e-02,\n",
       "       6.25143170e-02, 4.62025940e-02, 3.41470529e-02, 2.52371377e-02,\n",
       "       1.86520669e-02, 1.37852242e-02, 1.01882760e-02, 7.52987161e-03,\n",
       "       5.56511880e-03, 4.11302462e-03, 3.03982217e-03, 2.24664807e-03,\n",
       "       1.66043514e-03, 1.22718145e-03, 9.06975702e-04, 6.70320530e-04,\n",
       "       4.95415271e-04, 3.66147656e-04, 2.70609555e-04, 2.00000000e-04])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = 10**np.linspace(10,-3,100)*0.2\n",
    "alphas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Asociado con cada valor de alfa hay un vector de coeficientes de la regresión de Ridge, que se almacenaran en una matriz de coeficientes `coefs`. En este caso, es una matriz de $10 \\times 100$ con 10 filas (una para cada predictor) y 100 columnas (una para cada alfa). Aqui es importante standarizar las variables para que ellas esten en la misma escala, para ello usamos el argumento `normalize = True`:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1, 10)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = Ridge(normalize = True)\n",
    "coefs = []\n",
    "\n",
    "for a in alphas:\n",
    "    ridge.set_params(alpha = a)\n",
    "    ridge.fit(X, y)\n",
    "    coefs.append(ridge.coef_)\n",
    "    \n",
    "np.shape(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**Cambiamos la forma de la matriz 3D a 2D de acuerdo a lo comentado arriba**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 10)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#A.reshape(a,-1)\n",
    "coefs=np.array(coefs)\n",
    "coef=coefs.reshape(100, 1*10)\n",
    "np.shape(coef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.131892e-07</td>\n",
       "      <td>1.058616e-08</td>\n",
       "      <td>4.596372e-07</td>\n",
       "      <td>3.212128e-07</td>\n",
       "      <td>1.127641e-07</td>\n",
       "      <td>7.283444e-08</td>\n",
       "      <td>-2.867601e-07</td>\n",
       "      <td>2.928850e-07</td>\n",
       "      <td>4.556684e-07</td>\n",
       "      <td>2.961971e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.531505e-07</td>\n",
       "      <td>1.432357e-08</td>\n",
       "      <td>6.219111e-07</td>\n",
       "      <td>4.346163e-07</td>\n",
       "      <td>1.525753e-07</td>\n",
       "      <td>9.854847e-08</td>\n",
       "      <td>-3.880001e-07</td>\n",
       "      <td>3.962874e-07</td>\n",
       "      <td>6.165411e-07</td>\n",
       "      <td>4.007688e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.072199e-07</td>\n",
       "      <td>1.938048e-08</td>\n",
       "      <td>8.414754e-07</td>\n",
       "      <td>5.880566e-07</td>\n",
       "      <td>2.064416e-07</td>\n",
       "      <td>1.333408e-07</td>\n",
       "      <td>-5.249827e-07</td>\n",
       "      <td>5.361958e-07</td>\n",
       "      <td>8.342096e-07</td>\n",
       "      <td>5.422594e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.803784e-07</td>\n",
       "      <td>2.622271e-08</td>\n",
       "      <td>1.138556e-06</td>\n",
       "      <td>7.956686e-07</td>\n",
       "      <td>2.793254e-07</td>\n",
       "      <td>1.804165e-07</td>\n",
       "      <td>-7.103267e-07</td>\n",
       "      <td>7.254985e-07</td>\n",
       "      <td>1.128725e-06</td>\n",
       "      <td>7.337029e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.793654e-07</td>\n",
       "      <td>3.548058e-08</td>\n",
       "      <td>1.540521e-06</td>\n",
       "      <td>1.076578e-06</td>\n",
       "      <td>3.779406e-07</td>\n",
       "      <td>2.441121e-07</td>\n",
       "      <td>-9.611060e-07</td>\n",
       "      <td>9.816341e-07</td>\n",
       "      <td>1.527219e-06</td>\n",
       "      <td>9.927350e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>-3.145818e+01</td>\n",
       "      <td>-3.096283e+02</td>\n",
       "      <td>5.540991e+02</td>\n",
       "      <td>2.671526e+02</td>\n",
       "      <td>-8.361253e+02</td>\n",
       "      <td>3.335210e+02</td>\n",
       "      <td>2.084440e+02</td>\n",
       "      <td>2.810360e+02</td>\n",
       "      <td>7.581712e+02</td>\n",
       "      <td>1.332192e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>-3.156438e+01</td>\n",
       "      <td>-3.097253e+02</td>\n",
       "      <td>5.540258e+02</td>\n",
       "      <td>2.672260e+02</td>\n",
       "      <td>-8.513978e+02</td>\n",
       "      <td>3.456055e+02</td>\n",
       "      <td>2.153244e+02</td>\n",
       "      <td>2.829484e+02</td>\n",
       "      <td>7.635243e+02</td>\n",
       "      <td>1.332650e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>-3.164528e+01</td>\n",
       "      <td>-3.097979e+02</td>\n",
       "      <td>5.539670e+02</td>\n",
       "      <td>2.672814e+02</td>\n",
       "      <td>-8.630907e+02</td>\n",
       "      <td>3.548629e+02</td>\n",
       "      <td>2.205887e+02</td>\n",
       "      <td>2.844063e+02</td>\n",
       "      <td>7.676219e+02</td>\n",
       "      <td>1.333009e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>-3.170645e+01</td>\n",
       "      <td>-3.098521e+02</td>\n",
       "      <td>5.539209e+02</td>\n",
       "      <td>2.673229e+02</td>\n",
       "      <td>-8.719646e+02</td>\n",
       "      <td>3.618914e+02</td>\n",
       "      <td>2.245819e+02</td>\n",
       "      <td>2.855092e+02</td>\n",
       "      <td>7.707312e+02</td>\n",
       "      <td>1.333285e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>-3.175243e+01</td>\n",
       "      <td>-3.098924e+02</td>\n",
       "      <td>5.538853e+02</td>\n",
       "      <td>2.673540e+02</td>\n",
       "      <td>-8.786543e+02</td>\n",
       "      <td>3.671915e+02</td>\n",
       "      <td>2.275912e+02</td>\n",
       "      <td>2.863387e+02</td>\n",
       "      <td>7.730750e+02</td>\n",
       "      <td>1.333496e+02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0             1             2             3             4  \\\n",
       "0   1.131892e-07  1.058616e-08  4.596372e-07  3.212128e-07  1.127641e-07   \n",
       "1   1.531505e-07  1.432357e-08  6.219111e-07  4.346163e-07  1.525753e-07   \n",
       "2   2.072199e-07  1.938048e-08  8.414754e-07  5.880566e-07  2.064416e-07   \n",
       "3   2.803784e-07  2.622271e-08  1.138556e-06  7.956686e-07  2.793254e-07   \n",
       "4   3.793654e-07  3.548058e-08  1.540521e-06  1.076578e-06  3.779406e-07   \n",
       "..           ...           ...           ...           ...           ...   \n",
       "95 -3.145818e+01 -3.096283e+02  5.540991e+02  2.671526e+02 -8.361253e+02   \n",
       "96 -3.156438e+01 -3.097253e+02  5.540258e+02  2.672260e+02 -8.513978e+02   \n",
       "97 -3.164528e+01 -3.097979e+02  5.539670e+02  2.672814e+02 -8.630907e+02   \n",
       "98 -3.170645e+01 -3.098521e+02  5.539209e+02  2.673229e+02 -8.719646e+02   \n",
       "99 -3.175243e+01 -3.098924e+02  5.538853e+02  2.673540e+02 -8.786543e+02   \n",
       "\n",
       "               5             6             7             8             9  \n",
       "0   7.283444e-08 -2.867601e-07  2.928850e-07  4.556684e-07  2.961971e-07  \n",
       "1   9.854847e-08 -3.880001e-07  3.962874e-07  6.165411e-07  4.007688e-07  \n",
       "2   1.333408e-07 -5.249827e-07  5.361958e-07  8.342096e-07  5.422594e-07  \n",
       "3   1.804165e-07 -7.103267e-07  7.254985e-07  1.128725e-06  7.337029e-07  \n",
       "4   2.441121e-07 -9.611060e-07  9.816341e-07  1.527219e-06  9.927350e-07  \n",
       "..           ...           ...           ...           ...           ...  \n",
       "95  3.335210e+02  2.084440e+02  2.810360e+02  7.581712e+02  1.332192e+02  \n",
       "96  3.456055e+02  2.153244e+02  2.829484e+02  7.635243e+02  1.332650e+02  \n",
       "97  3.548629e+02  2.205887e+02  2.844063e+02  7.676219e+02  1.333009e+02  \n",
       "98  3.618914e+02  2.245819e+02  2.855092e+02  7.707312e+02  1.333285e+02  \n",
       "99  3.671915e+02  2.275912e+02  2.863387e+02  7.730750e+02  1.333496e+02  \n",
       "\n",
       "[100 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B=pd.DataFrame(coef)\n",
    "B"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**Esperamos que los coeficientes estimados sean más pequeños, en términos de la normalización $l_2$, cuando un valor grande de alfa es usado, comparado con el uso de valores pequeños de alfa, Veamos gráficamente:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'coeficientes')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax = plt.gca()\n",
    "ax.plot(alphas, coef, 'o')\n",
    "ax.set_xscale('log')\n",
    "plt.axis('tight')\n",
    "plt.xlabel('alpha')\n",
    "plt.ylabel('coeficientes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**Vamos a separar las muestras en un set de entranamiento y una de prueba con el fin de estimar el error de la regresión.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Split data into training and test sets\n",
    "X_train, X_test , y_train, y_test = train_test_split(X, y, test_size=0.5, random_state=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**Realicemos el ajuste construyendo un modelo de Regresión Ridge utilizando el set de entrenamiento, y evaluamos su MSE sobre set de prueba, usando $\\lambda = 1$ (arbitrario):**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Coefs\n",
      "age  -26.836294\n",
      "sex  -93.835342\n",
      "bmi  307.390511\n",
      "bp   183.122104\n",
      "s1     1.306202\n",
      "s2   -39.898895\n",
      "s3  -113.329300\n",
      "s4    95.836306\n",
      "s5   268.793764\n",
      "s6   136.456722\n",
      "3553.2867895757336\n"
     ]
    }
   ],
   "source": [
    "ridge2 = Ridge(alpha = 1, normalize = True) # Descripción del modelo\n",
    "ridge2.fit(X_train, y_train)             # Ajuste del modelo con el set de entrenamiento\n",
    "pred2 = ridge2.predict(X_test)           # Usamos el modelo para predecir sobre los datos de prueba\n",
    "print(pd.DataFrame(ridge2.coef_.T, index = X.columns, columns=['Coefs'])) # imprimos los coeficientes\n",
    "print(mean_squared_error(y_test, pred2))          # Calculamos el MSE sobre los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**El test-MSE cuando $\\lambda = 1$ es de $3664$. Ahora veamos que pasa si usamos un valor grande de alfa, $\\lambda = 10^{4}$:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Coefs\n",
      "age  0.020180\n",
      "sex  0.010842\n",
      "bmi  0.099763\n",
      "bp   0.073533\n",
      "s1   0.029014\n",
      "s2   0.026966\n",
      "s3  -0.076600\n",
      "s4   0.082118\n",
      "s5   0.111722\n",
      "s6   0.043525\n",
      "5582.434715594439\n"
     ]
    }
   ],
   "source": [
    "ridge3 = Ridge(alpha = 10**4, normalize = True) # Descripción del modelo\n",
    "ridge3.fit(X_train, y_train)             # Ajuste del modelo con el set de entrenamientoa\n",
    "pred3 = ridge3.predict(X_test)           # Usamos el modelo para predecir sobre los datos de prueba\n",
    "print(pd.DataFrame(ridge3.coef_.T, index = X.columns, columns=['Coefs'])) # Imprimimos los coeficientes\n",
    "print(mean_squared_error(y_test, pred3))          # Calculamos el MSE sobre los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=green>**Valores muy grandes de alfa reduce los coeficientes prácticamente hasta obtener el modelo nulo (el modelo contiene solo el intercepto y los demás coeficientes son cero), El resultado es un aumento del sesgo reflejado en un muy alto MSE.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**Veamos ahora que pasa con el MSE si utilizamos un valor de alfa igual a cero $\\lambda = 0$. Esta condición garantiza que la Regresión Ridge se convierta en una Regraesión por Mínimos Cuadrados Ordinaria.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Coefs\n",
      "age -140.582624\n",
      "sex -402.621847\n",
      "bmi  427.752774\n",
      "bp   425.293000\n",
      "s1  -567.363179\n",
      "s2   199.363646\n",
      "s3   -73.571747\n",
      "s4   203.671047\n",
      "s5   981.031986\n",
      "s6   -55.657345\n",
      "3732.9093096769716\n"
     ]
    }
   ],
   "source": [
    "ridge4 = Ridge(alpha = 0, normalize = True) # Descripción del modelo\n",
    "ridge4.fit(X_train, y_train)             # Ajuste del modelo con el set de entrenamientoa\n",
    "pred4 = ridge4.predict(X_test)           # Usamos el modelo para predecir sobre los datos de prueba\n",
    "print(pd.DataFrame(ridge4.coef_.T, index = X.columns, columns=['Coefs'])) # Imprimimos los coeficientes\n",
    "print(mean_squared_error(y_test, pred4))          # Calculamos el MSE sobre los datos de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=red>**Parece que, efectivamente, la regresión Ridge logra mejorar respecto a los mínimos cuadrados normales. Sin embargo, en lugar de elegir arbitrariamente alfa, podríamos utilizar la validación cruzada para elegir el parámetro de ajuste alfa más adecuado. Podemos hacerlo utilizando la función `RidgeCV()`. Por defecto, la función realiza una validación cruzada generalizada (una forma eficiente de LOOCV), aunque esto puede cambiarse utilizando el argumento argumento `cv`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2834948325853604"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridgecv = RidgeCV(alphas = alphas, scoring = 'neg_mean_squared_error', normalize = True)\n",
    "ridgecv.fit(X_train, y_train)\n",
    "ridgecv.alpha_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**Obtenemos el valor de alfa que genera el mas pequeño MSE, podemos utilizar este valor de alfa para determinar el test-MSE.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3141.383218350625"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge5 = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "ridge5.fit(X_train, y_train)\n",
    "mean_squared_error(y_test, ridge5.predict(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.array(X)\n",
    "y=np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE. 1 on the test set: 2996.9541942944584\n",
      "MSE. 2 on the test set: 2314.42488060453\n",
      "MSE. 3 on the test set: 3336.9471511901693\n",
      "MSE. 4 on the test set: 2790.9505142743537\n",
      "MSE. 5 on the test set: 3305.288852925357\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import KFold\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42) # Vamos hacer 5 separaciones sin barajar en cada separación\n",
    "ridge6 = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "x_traint = [] # Creamos arreglos de cada grupo de datos en los que almacenamos las diferentes divisiones \n",
    "x_testt = [] # Luego podremos utilizar la mejor separación para obtener el modelo más apropiado\n",
    "y_traint = []\n",
    "y_testt = []\n",
    "mses = []\n",
    "i = 1\n",
    "for train_index, test_index in kf.split(X):\n",
    "    x_train = X[train_index]\n",
    "    x_test = X[test_index]\n",
    "    y_train = y[train_index]\n",
    "    y_test = y[test_index]\n",
    "    ridge6.fit(x_train, y_train) #\n",
    "    mse = mean_squared_error(y_test, ridge6.predict(x_test))\n",
    "        \n",
    "    # Almacenamos cada grupo en los arreglos creados\n",
    "    x_traint.append(x_train) \n",
    "    x_testt.append(x_test)\n",
    "    y_traint.append(y_train)\n",
    "    y_testt.append(y_test)\n",
    "    mses.append(mse)\n",
    "   \n",
    "    # Entrenamos el modelo para cada separación the model\n",
    "    ridge6.fit(x_train, y_train) #Training the model\n",
    "    print(f\"MSE. {i} on the test set: {mean_squared_error(y_test, ridge6.predict(x_test))}\")\n",
    "    \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2314.42488060453"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_tr=np.array(y_traint[mses.index(min(mses))]) # Escogemos el mejor set a partir del que presente el\n",
    "y_te=np.array(y_testt[mses.index(min(mses))]) # el valor máximo de r2. Podríamos también elegir el que\n",
    "X_tr=np.array(x_traint[mses.index(min(mses))]) # presente el menor valor del mse\n",
    "X_te=np.array(x_testt[mses.index(min(mses))])\n",
    "\n",
    "ridge7 = Ridge(alpha = ridgecv.alpha_, normalize = True)\n",
    "ridge7.fit(X_tr, y_tr)\n",
    "mean_squared_error(y_te, ridge7.predict(X_te))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=blue>**El resultado representa una mejora adicional sobre el MSE de prueba que obtuvimos utilizando $\\lambda = 1$. Por último, volvemos a ajustar nuestro modelo de Regresión Ridge para obtener los coeficientes utilizando el mejor valor de alfa.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coefs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-46.050979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>-291.883207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bmi</th>\n",
       "      <td>401.434475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bp</th>\n",
       "      <td>286.660611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s1</th>\n",
       "      <td>-60.418926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s2</th>\n",
       "      <td>-187.173230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s3</th>\n",
       "      <td>-184.851095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s4</th>\n",
       "      <td>116.267190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s5</th>\n",
       "      <td>533.910106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>s6</th>\n",
       "      <td>107.470393</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Coefs\n",
       "age  -46.050979\n",
       "sex -291.883207\n",
       "bmi  401.434475\n",
       "bp   286.660611\n",
       "s1   -60.418926\n",
       "s2  -187.173230\n",
       "s3  -184.851095\n",
       "s4   116.267190\n",
       "s5   533.910106\n",
       "s6   107.470393"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge5.fit(X, y)\n",
    "pd.DataFrame(ridge5.coef_.T, index = X.columns, columns=['Coefs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
